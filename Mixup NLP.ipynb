{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/storage/imdb_sample/data_save.pkl'),\n",
       " PosixPath('/storage/imdb_sample/texts.csv')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "                .split_from_df(col=2)\n",
    "                .label_from_df(cols=0)\n",
    "                .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \\n \\n  xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , xxunk bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no matter how warm and gooey xxmaj raising xxmaj</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj many neglect that this is n't just a classic due to the fact that it 's the first xxup 3d game , or even the first xxunk - up . xxmaj it 's also one of the first xxunk games , one of the xxunk definitely the first ) truly claustrophobic games , and just a pretty well - xxunk gaming experience in general . xxmaj with graphics</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos i had read many good things about this adaptation of my favorite novel ... so xxunk my expectations were crushed . xxmaj but they were crushed more than should be expected . xxmaj the movie would have been a decent movie if i had not read the novel xxunk , which perhaps ruined it for me . \\n \\n  xxmaj in any event , for some reason they</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj this is the last of four xxunk from xxmaj france i 've xxunk for viewing during this xxmaj christmas season : the others ( in order of viewing ) were the uninspired xxup the xxup black xxup xxunk ( 1964 ; from the same director as this one but not nearly as good ) , the surprisingly effective xxup lady xxmaj oscar ( 1979 ; which had xxunk</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data, AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if I try to use MixUp on text data? Let's see by adding some debug prints on the original callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixUpCallback(LearnerCallback):\n",
    "    \"Callback that creates the mixed-up input and target.\"\n",
    "    def __init__(self, learn:Learner, alpha:float=0.4, stack_x:bool=False, stack_y:bool=True):\n",
    "        super().__init__(learn)\n",
    "        self.alpha,self.stack_x,self.stack_y = alpha,stack_x,stack_y\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        if self.stack_y: self.learn.loss_func = MixUpLoss(self.learn.loss_func)\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "\n",
    "        \"Applies mixup to `last_input` and `last_target` if `train`.\"\n",
    "        if not train: return\n",
    "        lambd = np.random.beta(self.alpha, self.alpha, last_target.size(0))\n",
    "        lambd = np.concatenate([lambd[:,None], 1-lambd[:,None]], 1).max(1)\n",
    "        lambd = last_input.float().new(lambd)\n",
    "        shuffle = torch.randperm(last_target.size(0)).to(last_input.device)\n",
    "        x1, y1 = last_input[shuffle], last_target[shuffle]\n",
    "        if self.stack_x:\n",
    "            new_input = [[last_input, last_input[shuffle], lambd]]\n",
    "        else: \n",
    "            out_shape = [lambd.size(0)] + [1 for _ in range(len(x1.shape) - 1)]\n",
    "            new_input = (last_input * lambd.view(out_shape) + x1 * (1-lambd).view(out_shape))\n",
    "        if self.stack_y:\n",
    "            new_target = torch.cat([last_target[:,None].float(), y1[:,None].float(), lambd[:,None].float()], 1)\n",
    "        else:\n",
    "            if len(last_target.shape) == 2:\n",
    "                lambd = lambd.unsqueeze(1).float()\n",
    "            new_target = last_target.float() * lambd + y1.float() * (1-lambd)\n",
    "        return {'last_input': new_input, 'last_target': new_target}  \n",
    "    \n",
    "    def on_train_end(self, **kwargs):\n",
    "        if self.stack_y: self.learn.loss_func = self.learn.loss_func.get_old()\n",
    "            \n",
    "class MixUpLoss(Module):\n",
    "    \"Adapt the loss function `crit` to go with mixup.\"\n",
    "    \n",
    "    def __init__(self, crit, reduction='mean'):\n",
    "        super().__init__()\n",
    "        if hasattr(crit, 'reduction'): \n",
    "            self.crit = crit\n",
    "            self.old_red = crit.reduction\n",
    "            setattr(self.crit, 'reduction', 'none')\n",
    "        else: \n",
    "            self.crit = partial(crit, reduction='none')\n",
    "            self.old_crit = crit\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        if len(target.size()) == 2:\n",
    "            loss1, loss2 = self.crit(output,target[:,0].long()), self.crit(output,target[:,1].long())\n",
    "            d = loss1 * target[:,2] + loss2 * (1-target[:,2])\n",
    "        else:  d = self.crit(output, target)\n",
    "        if self.reduction == 'mean':    return d.mean()\n",
    "        elif self.reduction == 'sum':   return d.sum()\n",
    "        return d\n",
    "    \n",
    "    def get_old(self):\n",
    "        if hasattr(self, 'old_crit'):  return self.old_crit\n",
    "        elif hasattr(self, 'old_red'): \n",
    "            setattr(self.crit, 'reduction', self.old_red)\n",
    "            return self.crit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "testMixup = MixUpCallback(learn)\n",
    "xb,yb = data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    5, 2739,  ...,    0,   10,   24],\n",
       "        [   1,    1,    1,  ...,  810,  104,   10],\n",
       "        [   1,    1,    1,  ...,    0,   55,   10],\n",
       "        [   1,    1,    1,  ...,  303,  163,   10]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = testMixup.on_batch_begin(xb.cuda(),yb.cuda(),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the numbers of the distribution are ints and get rounded to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    5, 2739,  ...,    0,   10,   24],\n",
       "        [   1,    1,    1,  ...,  122,  169,   34],\n",
       "        [   1,    1,    1,  ...,  810,  104,   10],\n",
       "        [   1,    1,    1,  ...,   10,    6, 4810]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['last_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    5, 2739,  ...,    0,   10,   24],\n",
       "        [   1,    1,    1,  ...,  810,  104,   10],\n",
       "        [   1,    1,    1,  ...,  122,  169,   34],\n",
       "        [   1,    1,    1,  ...,   10,    6, 4810]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means we get the same batch, but shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea: Let's make a MixUp function that runs just after calculating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(x, x1, lambd):\n",
    "    x = lambd[:,None,None] * x + (1 - lambd[:,None,None]) * x1\n",
    "    return x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMixup = MixUpCallback(learn,stack_x=True)\n",
    "xb,yb = data.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.new([0.1,0.2])[:,None,None].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = testMixup.on_batch_begin(xb.cuda(),yb.cuda(),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[   2,    5, 2739,  ...,    0,   10,   24],\n",
       "         [   1,    1,    1,  ...,  121,   58,   10],\n",
       "         [   1,    1,    1,  ...,   15,  126,   34],\n",
       "         [   1,    1,    1,  ...,   12,  566,   10]], device='cuda:0'),\n",
       " tensor([[   2,    5, 2739,  ...,    0,   10,   24],\n",
       "         [   1,    1,    1,  ...,   15,  126,   34],\n",
       "         [   1,    1,    1,  ...,   12,  566,   10],\n",
       "         [   1,    1,    1,  ...,  121,   58,   10]], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0], device='cuda:0')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['last_input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we use stack_x we run into the problem of the lambdas being calculated as ints, let's modify the callback\n",
    "by adding .float() after         \n",
    "lambd = last_input.new(lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[   2,    5, 2739,  ...,    0,   10,   24],\n",
       "          [   1,    1,    1,  ...,  810,  104,   10],\n",
       "          [   1,    1,    1,  ...,   15,  126,   34],\n",
       "          [   1,    1,    1,  ...,   96,   20,   10]], device='cuda:0'),\n",
       "  tensor([[   2,    5, 2739,  ...,    0,   10,   24],\n",
       "          [   1,    1,    1,  ...,  810,  104,   10],\n",
       "          [   1,    1,    1,  ...,   15,  126,   34],\n",
       "          [   1,    1,    1,  ...,   96,   20,   10]], device='cuda:0'),\n",
       "  tensor([0.9986, 0.9945, 0.7907, 0.9848], device='cuda:0')]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testMixup = MixUpCallback(learn,stack_x=True)\n",
    "a = testMixup.on_batch_begin(xb.cuda(),yb.cuda(),True)\n",
    "a['last_input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and let's modify AWD_LSTM forward pass to do MixUp if a list of tensors is passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, input:Tensor, from_embeddings:bool=False)->Tuple[List[Tensor],List[Tensor]]:\n",
    "    use_mixup = False\n",
    "    if from_embeddings: bs,sl,es = input.size()\n",
    "    elif isinstance(input, list):\n",
    "        use_mixup = True\n",
    "        bs,sl = input[0].size()\n",
    "    else: bs,sl = input.size()\n",
    "    if bs!=self.bs:\n",
    "        self.bs=bs\n",
    "        self.reset()\n",
    "    if use_mixup:    \n",
    "        input,in1,lambd = input\n",
    "        input = self.encoder_dp(input)\n",
    "        in1 = self.encoder_dp(in1)\n",
    "        raw_output = mixup(input,in1,lambd)\n",
    "    else:\n",
    "        raw_output = self.input_dp(input if from_embeddings else self.encoder_dp(input))\n",
    "    new_hidden,raw_outputs,outputs = [],[],[]\n",
    "    for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "        raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "        new_hidden.append(new_h)\n",
    "        raw_outputs.append(raw_output)\n",
    "        if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "        outputs.append(raw_output)\n",
    "    self.hidden = to_detach(new_hidden, cpu=False)\n",
    "    return raw_outputs, outputs\n",
    "AWD_LSTM.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And MultiBatchEncoder forward to accept lists as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, input:LongTensor,from_embeddings:bool=False)->Tuple[List[Tensor],List[Tensor],Tensor]:\n",
    "    use_mixup = False\n",
    "    if isinstance(input, list): \n",
    "        bs,sl = input[0].size() \n",
    "        use_mixup = True\n",
    "    else: bs,sl = input.size()\n",
    "    self.reset()\n",
    "    raw_outputs,outputs,masks = [],[],[]\n",
    "    for i in range(0, sl, self.bptt):\n",
    "        if use_mixup:\n",
    "            r, o = self.module([input[0][:,i: min(i+self.bptt, sl)],input[1][:,i: min(i+self.bptt, sl)],input[2]])\n",
    "        else:\n",
    "            r, o = self.module(input[:,i: min(i+self.bptt, sl)])\n",
    "        if i>(sl-self.max_len):\n",
    "            if use_mixup:\n",
    "                masks.append(input[0][:,i: min(i+self.bptt, sl)] == self.pad_idx)\n",
    "            else:\n",
    "                masks.append(input[:,i: min(i+self.bptt, sl)] == self.pad_idx)\n",
    "            raw_outputs.append(r)\n",
    "            outputs.append(o)\n",
    "    return self.concat(raw_outputs),self.concat(outputs),torch.cat(masks,dim=1)\n",
    "MultiBatchEncoder.forward = forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data, AWD_LSTM, drop_mult=0.5)\n",
    "learn.callback_fns.append(partial(MixUpCallback, alpha=0.4, stack_x=True, stack_y=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.715994</td>\n",
       "      <td>0.740792</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
